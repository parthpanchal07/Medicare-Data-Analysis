{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import requests\n",
    "import os\n",
    "import csv\n",
    "import zipfile\n",
    "import openpyxl\n",
    "import sqlite3\n",
    "import glob\n",
    "import getpass\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#URL to get the dataset\n",
    "url=\"https://data.medicare.gov/views/bg9k-emty/files/0a9879e0-3312-4719-a1db-39fd114890f1?content_type=application%2Fzip%3B%20charset%3Dbinary&filename=Hospital_Revised_Flatfiles.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a staging subdirectory called “staging”\n",
    "staging_dir_name = \"staging\"\n",
    "if not os.path.isdir(staging_dir_name):\n",
    "    os.mkdir(staging_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check if staging subdirectory is created\n",
    "if os.path.isdir(staging_dir_name):\n",
    "    zip_file_name = os.path.join(staging_dir_name, \"test.zip\")\n",
    "    zf = open(zip_file_name,\"wb\")\n",
    "    zf.write(r.content)\n",
    "    zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract all files from the zipped file\n",
    "z = zipfile.ZipFile(zip_file_name,'r')\n",
    "z.extractall(staging_dir_name)\n",
    "z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert encoding type cp1252 to utf-8\n",
    "for filename in glob.glob(os.path.join(staging_dir_name, \"*.csv\")):\n",
    "    in_fp = open(filename,\"rt\",encoding='cp1252')\n",
    "    input_data = in_fp.read()\n",
    "    in_fp.close()\n",
    "    \n",
    "    out_fp = open(filename,\"wt\",encoding='utf-8')\n",
    "    for c in input_data:\n",
    "        if c!= '\\0':\n",
    "            out_fp.write(c)\n",
    "    out_fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create DB\n",
    "conn = sqlite3.connect(\"medicare_hospital_compare.db\")\n",
    "conn.text_factory = str  # allows utf-8 data to be stored\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This method gives all the csv files in the directory to the fileToTable method  \n",
    "def CallFileToTable(dirname, db):\n",
    "    for filename in glob.glob(os.path.join(dirname, '*.csv')):\n",
    "        fileToTable(filename, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Method to create a table for a csv file with hearers as column name\n",
    "def fileToTable(filename, db):\n",
    "        with open(filename, encoding=\"utf8\") as f:\n",
    "            with db:\n",
    "                data = csv.DictReader(f)\n",
    "                cols23 = data.fieldnames\n",
    "                cols = list()\n",
    "                #Replace blank space, -, / with _ and % with pct, convert to lower case\n",
    "                table= (((str.lower(os.path.splitext(os.path.basename(filename))[0]).replace(\" \", \"_\")).replace(\"-\", \"_\")).replace(\"%\", \"pct\")).replace('/', '_')\n",
    "                if  not table[0].isalpha():\n",
    "                    table = \"t_\" + table\n",
    "                #Replace blank space, -, / with _ and % with pct, convert to lower case\n",
    "                for col in cols23:\n",
    "                    col = str.lower((((col.replace(\" \", \"_\")).replace(\"-\", \"_\")).replace(\"%\", \"pct\")).replace('/', '_'))\n",
    "                    #Prepend c_ if the initial letter of the column name is not an alphabet\n",
    "                    if  not col[0].isalpha():\n",
    "                        col = \"c_\" + col\n",
    "                    cols.append(col)\n",
    "                \n",
    "                #If a table already exists, drop it                  \n",
    "                sql = 'drop table if exists \"{}\"'.format(table)\n",
    "                db.execute(sql)\n",
    "                \n",
    "                #Create Table \n",
    "                sql = 'create table \"{table}\" ( {cols} )'.format(\n",
    "                    table=table,\n",
    "                    cols=','.join('\"{}\"'.format(col) for col in cols))\n",
    "                db.execute(sql)\n",
    "                \n",
    "                #Insert data into tables\n",
    "                sql = 'insert into \"{table}\" values ( {vals} )'.format(\n",
    "                    table=table,\n",
    "                    vals=','.join('?' for col in cols))\n",
    "                db.executemany(sql, (list(map(row.get, cols23)) for row in data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create table for each CSV file\n",
    "CallFileToTable(staging_dir_name, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_url = \"http://kevincrook.com/utd/hospital_ranking_focus_states.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(k_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xf = open(\"hospital_ranking_focus_states.xlsx\", \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85117"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xf.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the excel file and call it xls_file\n",
    "xls_file = pd.ExcelFile('hospital_ranking_focus_states.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the xls file's Sheet1 as a dataframe\n",
    "df = xls_file.parse(xls_file.sheet_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(list(df)[1], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfalldata = (pd.read_sql_query(\"select provider_id as [Provider ID], hospital_name as [Hospital Name], city as City, state as State, county_name as County from hospital_general_information;\", conn)).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "while ctr < 1000:\n",
    "    a = int(dff['Provider ID'].iloc[[ctr]].str.len())\n",
    "    if a == 5:\n",
    "        dff['Provider ID'].iloc[[ctr]] = '0' + dff['Provider ID'].iloc[[ctr]]\n",
    "    ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = dff.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.merge(df1, dfalldata, on ='Provider ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = df2[['Provider ID', 'Hospital Name', 'City', 'State', 'County']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('hospital_ranking.xlsx', engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df3.to_excel(writer, sheet_name='Nationwide', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4 = xls_file.parse(xls_file.sheet_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df5 = pd.merge(dff, dfalldata, on ='Provider ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df6 = df5[['Provider ID', 'Hospital Name', 'City', 'State', 'County']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df4.iterrows():\n",
    "    df7 = df6.loc[df6['State'] == row['State Abbreviation']]\n",
    "    df7 = df7.head(100)\n",
    "    # Convert the dataframe to an XlsxWriter Excel object.\n",
    "    df7.to_excel(writer, sheet_name=row['State Name'], index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_url = \"http://kevincrook.com/utd/hospital_ranking_focus_states.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(k_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xf = open(\"hospital_ranking_focus_states.xlsx\", \"wb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85117"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xf.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the excel file and call it xls_file\n",
    "xls_file = pd.ExcelFile('hospital_ranking_focus_states.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfNationalMeasureData = (pd.read_sql_query(\"select state as State, measure_id as [Measure ID], measure_name as [Measure Name], score as Score from timely_and_effective_care___hospital order by measure_id;\", conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfNational = (pd.read_sql_query(\"select distinct measure_id as [Measure ID], measure_name as [Measure Name] from timely_and_effective_care___hospital order by [Measure ID];\", conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert Series datatype to numeric, getting rid of any non-numeric values\n",
    "dfNation = dfNationalMeasureData[dfNationalMeasureData[['Score']].apply(pd.to_numeric, errors='coerce').notnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfNationwide = dfNation[['Measure ID','Score']]\n",
    "dfNationwide['Score'] = dfNationwide['Score'].astype(float)\n",
    "dfmean = dfNationwide.groupby(['Measure ID']).mean()\n",
    "dfmin = dfNationwide.groupby(['Measure ID']).min()\n",
    "dfmax = dfNationwide.groupby(['Measure ID']).max()\n",
    "dfstd = dfNationwide.groupby(['Measure ID']).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfmean = dfmean.rename(columns = {'Score':'Average'})\n",
    "dfmin = dfmin.rename(columns = {'Score':'Minimum'})\n",
    "dfmax = dfmax.rename(columns = {'Score':'Maximum'})\n",
    "dfstd = dfstd.rename(columns = {'Score':'Standard Deviation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfMeasure = pd.merge(dfNational, dfmin.reset_index(), on ='Measure ID', how='inner')\n",
    "dfMeasure = pd.merge(dfMeasure, dfmax.reset_index(), on ='Measure ID', how='inner')\n",
    "dfMeasure = pd.merge(dfMeasure, dfmean.reset_index(), on ='Measure ID', how='inner')\n",
    "dfMeasure = pd.merge(dfMeasure, dfstd.reset_index(), on ='Measure ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('measures_statistics.xlsx', engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "dfMeasure.to_excel(writer, sheet_name='Nationwide', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdf4 = xls_file.parse(xls_file.sheet_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in newdf4.iterrows():\n",
    "    newdfNation = dfNation.loc[dfNation['State'] == row['State Abbreviation']]\n",
    "    newdfNationwide = newdfNation[['Measure ID','Score']]\n",
    "    newdfNationwide['Score'] = newdfNationwide['Score'].astype(float)\n",
    "    newdfmean = newdfNationwide.groupby(['Measure ID']).mean()\n",
    "    newdfmin = newdfNationwide.groupby(['Measure ID']).min()\n",
    "    newdfmax = newdfNationwide.groupby(['Measure ID']).max()\n",
    "    newdfstd = newdfNationwide.groupby(['Measure ID']).std()\n",
    "    \n",
    "    newdfmean = newdfmean.rename(columns = {'Score':'Average'})\n",
    "    newdfmin = newdfmin.rename(columns = {'Score':'Minimum'})\n",
    "    newdfmax = newdfmax.rename(columns = {'Score':'Maximum'})\n",
    "    newdfstd = newdfstd.rename(columns = {'Score':'Standard Deviation'})\n",
    "    \n",
    "    newdfMeasure = pd.merge(dfNational, newdfmin.reset_index(), on ='Measure ID', how='inner')\n",
    "    newdfMeasure = pd.merge(newdfMeasure, newdfmax.reset_index(), on ='Measure ID', how='inner')\n",
    "    newdfMeasure = pd.merge(newdfMeasure, newdfmean.reset_index(), on ='Measure ID', how='inner')\n",
    "    newdfMeasure = pd.merge(newdfMeasure, newdfstd.reset_index(), on ='Measure ID', how='inner')\n",
    "    \n",
    "    # Convert the dataframe to an XlsxWriter Excel object.\n",
    "    newdfMeasure.to_excel(writer, sheet_name=row['State Name'], index = False)\n",
    "    \n",
    "#####################\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
